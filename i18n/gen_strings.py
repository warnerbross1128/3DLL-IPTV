from __future__ import annotations

"""
Collect user-facing strings (UI + logs) and emit a QT_TRANSLATE_NOOP inventory.

Why:
- We are not yet wiring every widget/message to self.tr(), but we still want a
  single .ts file listing everything that needs translation.
- Qt's lupdate understands QT_TRANSLATE_NOOP entries, so the generated file can
  be fed to lupdate/lrelease.

Usage:
    python i18n/gen_strings.py
Generates: i18n/strings_noop.py
"""

import ast
import json
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable

ROOT = Path(__file__).resolve().parent.parent
OUT_PATH = ROOT / "i18n" / "strings_noop.py"

EXCLUDED_DIRS = {".venv", "__pycache__", "node_modules", "Archives", "TESTS"}
LETTER_RE = re.compile(r"[A-Za-zÀ-ÿ]")


@dataclass(frozen=True, order=True)
class Entry:
    source: str  # relative path from repo root
    text: str


def _collect_docstrings(node: ast.AST) -> set[str]:
    docs: set[str] = set()
    if isinstance(node, (ast.Module, ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):
        doc = ast.get_docstring(node, clean=False)
        if doc:
            docs.add(doc)
    for child in ast.iter_child_nodes(node):
        docs |= _collect_docstrings(child)
    return docs


def _iter_strings(path: Path) -> Iterable[Entry]:
    """Yield candidate strings from one Python file."""
    try:
        tree = ast.parse(path.read_text(encoding="utf-8"))
    except Exception:
        return []

    docstrings = _collect_docstrings(tree)
    rel = path.relative_to(ROOT).as_posix()

    for node in ast.walk(tree):
        if not (isinstance(node, ast.Constant) and isinstance(node.value, str)):
            continue

        s = node.value
        if s in docstrings:
            continue
        if not s or not LETTER_RE.search(s):
            continue

        t = s.strip()
        if not t:
            continue

        lower = t.lower()
        if lower.startswith("http"):
            continue
        if t.startswith("#") and " " not in t:
            continue
        if "\n" in t:
            continue
        if len(t) <= 2:
            continue
        if t.startswith("/") or t.startswith("\\"):
            continue
        if t.endswith(".py"):
            continue
        if "pycache" in lower:
            continue
        if "\\" in t:
            continue
        if t.startswith("*."):
            continue
        # Keep short labels like "Stop" but drop lowercase tokens without spaces.
        if (" " not in t) and not t[0].isupper():
            continue

        yield Entry(rel, t)


def _iter_source_files() -> Iterable[Path]:
    for path in ROOT.rglob("*.py"):
        if any(part in EXCLUDED_DIRS for part in path.parts):
            continue
        yield path


def generate_strings() -> list[Entry]:
    entries: list[Entry] = []
    for path in _iter_source_files():
        entries.extend(_iter_strings(path))

    # Deduplicate on text while preserving deterministic ordering by (source, text).
    deduped: list[Entry] = []
    seen: set[str] = set()
    for entry in sorted(entries):
        if entry.text in seen:
            continue
        seen.add(entry.text)
        deduped.append(entry)
    return deduped


def write_inventory(entries: list[Entry]) -> None:
    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    lines: list[str] = [
        "# Auto-generated by i18n/gen_strings.py",
        "# Contains QT_TRANSLATE_NOOP entries so pyside6-lupdate can extract all UI/log text.",
        "from PySide6.QtCore import QT_TRANSLATE_NOOP",
        "",
        "STRINGS = [",
    ]

    for entry in entries:
        txt = json.dumps(entry.text, ensure_ascii=False)
        lines.append(f"    QT_TRANSLATE_NOOP('App', {txt}),  # {entry.source}")
    lines.append("]")
    lines.append("")

    OUT_PATH.write_text("\n".join(lines), encoding="utf-8")


def main() -> None:
    entries = generate_strings()
    write_inventory(entries)
    print(f"Collected {len(entries)} strings -> {OUT_PATH}")


if __name__ == "__main__":
    main()
